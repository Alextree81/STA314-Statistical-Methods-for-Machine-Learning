{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw4q3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB1EgKaS1lz-"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.special\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "# (PLEASE DO NOT CHANGE) Set random seed:\n",
        "np.random.seed(1746)\n",
        "\n",
        "PREFIX = \"digit_\"\n",
        "TEST_STEM = \"test_\"\n",
        "TRAIN_STEM = \"train_\"\n",
        "\n",
        "def load_data(data_dir, stem):\n",
        "    \"\"\"\n",
        "    Loads data from either the training set or the test set and returns the pixel values and\n",
        "    class labels\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    labels = []\n",
        "    for i in range(0, 10):\n",
        "      with urllib.request.urlopen(os.path.join(data_dir, PREFIX + stem + str(i) + \".txt\")) as f:\n",
        "        digits = np.loadtxt(f, delimiter=',')\n",
        "        digit_count = digits.shape[0]\n",
        "        data.append(digits)\n",
        "        labels.append(np.ones(digit_count) * i)\n",
        "    data, labels = np.array(data), np.array(labels)\n",
        "    data = np.reshape(data, (-1, 64))\n",
        "    labels = np.reshape(labels, (-1))\n",
        "    return data, labels\n",
        "\n",
        "def load_all_data(shuffle=True):\n",
        "    '''\n",
        "    Loads all data from the given data directory.\n",
        "\n",
        "    Returns four numpy arrays:\n",
        "        - train_data\n",
        "        - train_labels\n",
        "        - test_data\n",
        "        - test_labels\n",
        "    '''\n",
        "\n",
        "    train_data, train_labels = load_data(\"https://www.cs.toronto.edu/~cmaddis/courses/sta314_f21/data/\", TRAIN_STEM)\n",
        "    test_data, test_labels = load_data(\"https://www.cs.toronto.edu/~cmaddis/courses/sta314_f21/data/\", TEST_STEM)\n",
        "\n",
        "    if shuffle:\n",
        "        train_indices = np.random.permutation(train_data.shape[0])\n",
        "        test_indices = np.random.permutation(test_data.shape[0])\n",
        "        train_data, train_labels = train_data[train_indices], train_labels[train_indices]\n",
        "        test_data, test_labels = test_data[test_indices], test_labels[test_indices]\n",
        "\n",
        "    return train_data, train_labels, test_data, test_labels\n",
        "\n",
        "\n",
        "def get_digits_by_label(digits, labels, query_label):\n",
        "    '''\n",
        "    Return all digits in the provided array which match the query label\n",
        "\n",
        "    Input:\n",
        "        - digits: numpy array containing pixel values for digits\n",
        "        - labels: the corresponding digit labels (0-9)\n",
        "        - query_label: the digit label for all returned digits\n",
        "\n",
        "    Returns:\n",
        "        - Numpy array containing all digits matching the query label\n",
        "    '''\n",
        "    assert digits.shape[0] == labels.shape[0]\n",
        "\n",
        "    matching_indices = labels == query_label\n",
        "    return digits[matching_indices]\n",
        "\n",
        "def avg_conditional_likelihood(digits, labels, means, covariances):\n",
        "    '''\n",
        "    Compute the average conditional likelihood over the true class labels\n",
        "\n",
        "        AVG( log p(t^(i) | x^(i)) )\n",
        "\n",
        "    i.e. the average log likelihood that the model assigns to the correct class label.\n",
        "\n",
        "    Arguments\n",
        "        digits: size N x 64 numpy array with the images\n",
        "        labels: size N x 10 numpy array with the labels\n",
        "        means: size 10 x 64 numpy array with the 10 class means\n",
        "        covariances: size 10 x 64 x 64 numpy array with the 10 class covariances\n",
        "    \n",
        "    Returns\n",
        "        average conditional log-likelihood.\n",
        "    '''\n",
        "    cond_likelihood = conditional_likelihood(digits, means, covariances)\n",
        "\n",
        "    # Compute as described above and return\n",
        "    assert len(digits) == len(labels)\n",
        "    sample_size = len(digits)\n",
        "    total_prob = 0\n",
        "    for i in range(sample_size):\n",
        "        total_prob += cond_likelihood[i][int(labels[i])]\n",
        "\n",
        "    return total_prob/sample_size"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRAClSBL1pQC"
      },
      "source": [
        "def compute_mean_mles(train_data, train_labels):\n",
        "    '''\n",
        "    Compute the mean estimate for each digit class. You may iterate over\n",
        "    the possible digits (0 to 9), but otherwise make sure that your code\n",
        "    is vectorized.\n",
        "\n",
        "    Arguments\n",
        "        train_data: size N x 64 numpy array with the images\n",
        "        train_labels: size N numpy array with corresponding labels\n",
        "    \n",
        "    Returns\n",
        "        means: size 10 x 64 numpy array with the ith row corresponding\n",
        "               to the mean estimate for digit class i\n",
        "    '''\n",
        "    # Initialize array to store means\n",
        "    means = np.zeros((10, 64))\n",
        "    # == YOUR CODE GOES HERE ==\n",
        "    # ====\n",
        "    return means"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCMVh1Xl1tFE"
      },
      "source": [
        "def compute_sigma_mles(train_data, train_labels):\n",
        "    '''\n",
        "    Compute the covariance estimate for each digit class. You may iterate over\n",
        "    the possible digits (0 to 9), but otherwise make sure that your code\n",
        "    is vectorized.\n",
        "\n",
        "    Arguments\n",
        "        train_data: size N x 64 numpy array with the images\n",
        "        train_labels: size N numpy array with corresponding labels\n",
        "    \n",
        "    Returns\n",
        "        covariances: size 10 x 64 x 64 numpy array with the ith row corresponding\n",
        "               to the covariance matrix estimate for digit class i\n",
        "    '''\n",
        "    # Initialize array to store covariances\n",
        "    covariances = np.zeros((10, 64, 64))\n",
        "    # == YOUR CODE GOES HERE ==\n",
        "    # ====\n",
        "    return covariances"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWKLzBby1vHq"
      },
      "source": [
        "def generative_likelihood(digits, means, covariances):\n",
        "    '''\n",
        "    Compute the generative log-likelihood log p(x|t). You may iterate over\n",
        "    the possible digits (0 to 9), but otherwise make sure that your code\n",
        "    is vectorized.\n",
        "\n",
        "    Arguments\n",
        "        digits: size N x 64 numpy array with the images\n",
        "        means: size 10 x 64 numpy array with the 10 class means\n",
        "        covariances: size 10 x 64 x 64 numpy array with the 10 class covariances\n",
        "    \n",
        "    Returns\n",
        "        likelihoods: size N x 10 numpy array with the ith row corresponding\n",
        "               to logp(x^(i) | t) for t in {0, ..., 9}\n",
        "    '''\n",
        "    N = digits.shape[0]\n",
        "    likelihoods = np.zeros((N, 10))\n",
        "    # == YOUR CODE GOES HERE ==\n",
        "    # ====\n",
        "    return likelihoods"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHLCqymq1xts"
      },
      "source": [
        "def conditional_likelihood(digits, means, covariances):\n",
        "    '''\n",
        "    Compute the generative log-likelihood log p(t|x). Make sure that your code\n",
        "    is vectorized.\n",
        "\n",
        "    Arguments\n",
        "        digits: size N x 64 numpy array with the images\n",
        "        means: size 10 x 64 numpy array with the 10 class means\n",
        "        covariances: size 10 x 64 x 64 numpy array with the 10 class covariances\n",
        "    \n",
        "    Returns\n",
        "        likelihoods: size N x 10 numpy array with the ith row corresponding\n",
        "               to logp(t | x^(i)) for t in {0, ..., 9}\n",
        "    '''\n",
        "    # == YOUR CODE GOES HERE ==\n",
        "    # ====\n",
        "    pass"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZCODrQ11zNi"
      },
      "source": [
        "def classify_data(digits, means, covariances):\n",
        "    '''\n",
        "    Classify new points by taking the most likely posterior class. \n",
        "    Make sure that your code is vectorized.\n",
        "\n",
        "    Arguments\n",
        "        digits: size N x 64 numpy array with the images\n",
        "        means: size 10 x 64 numpy array with the 10 class means\n",
        "        covariances: size 10 x 64 x 64 numpy array with the 10 class covariances\n",
        "    \n",
        "    Returns\n",
        "        pred: size N numpy array with the ith element corresponding\n",
        "               to argmax_t log p(t | x^(i))\n",
        "    '''\n",
        "    # Compute and return the most likely class\n",
        "    # == YOUR CODE GOES HERE ==\n",
        "    # ====\n",
        "    pass"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r_kgjKL13bN"
      },
      "source": [
        "train_data, train_labels, test_data, test_labels = load_all_data()\n",
        "\n",
        "# Fit the model\n",
        "means = compute_mean_mles(train_data, train_labels)\n",
        "covariances = compute_sigma_mles(train_data, train_labels)\n",
        "\n",
        "# Evaluation\n",
        "train_log_llh = avg_conditional_likelihood(train_data, train_labels, means, covariances)\n",
        "test_log_llh = avg_conditional_likelihood(test_data, test_labels, means, covariances)\n",
        "\n",
        "print('Train average conditional log-likelihood: ', train_log_llh)\n",
        "print('Test average conditional log-likelihood: ', test_log_llh)\n",
        "\n",
        "train_posterior_result = classify_data(train_data, means, covariances)\n",
        "test_posterior_result = classify_data(test_data, means, covariances)\n",
        "\n",
        "train_accuracy = np.mean(train_labels.astype(int) == train_posterior_result)\n",
        "test_accuracy = np.mean(test_labels.astype(int) == test_posterior_result)\n",
        "\n",
        "print('Train posterior accuracy: ', train_accuracy)\n",
        "print('Test posterior accuracy: ', test_accuracy)\n",
        "\n",
        "for i in range(10):\n",
        "  (e_val, e_vec) = np.linalg.eig(covariances[i])\n",
        "  # In particular, note the axis to access the eigenvector\n",
        "  curr_leading_evec = e_vec[:,np.argmax(e_val)].reshape((8,8))\n",
        "  plt.subplot(3,4,i+1)\n",
        "  plt.imshow(curr_leading_evec, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}